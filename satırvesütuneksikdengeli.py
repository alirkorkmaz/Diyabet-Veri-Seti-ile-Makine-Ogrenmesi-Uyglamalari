# -*- coding: utf-8 -*-
"""SatırVeSütunEksikDengeli.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K0A3sO65wMqHskRZ1ZcUNzZlO5o-CqT0

### Kütüphanelerin İmport Edilmesi
"""

import numpy as np # linear algebra
import pandas as pd 
import matplotlib.pyplot as plt    # visualization library (görselleştirme kütüphanesi)
import seaborn as sns         # visualization library (görselleştirme kütüphanesi)
import missingno as msno      # visualization library (görselleştirme kütüphanesi)

from sklearn.preprocessing import RobustScaler # Standartlaştırma için kullanılan kütüphane 
from sklearn.model_selection import train_test_split  # veri setinin test ve train olarak ayrılması 
from imblearn.over_sampling import SMOTE # veri setinin dengeli hale gertirmek için kullanılan kütüphane 

# Makine öğrenmesi algoritmaları için gereken kütüphaneler 
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report,f1_score,recall_score,roc_auc_score, roc_curve
from sklearn.naive_bayes import BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier as randomForest
from sklearn.ensemble import GradientBoostingClassifier as gradientBoosting
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb
from xgboost import XGBClassifier as xgBoost
from xgboost import XGBClassifier
from sklearn import svm
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets, linear_model, metrics
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import roc_curve   # roc eğrisi için kullanılan kütüphane 
from sklearn.metrics import RocCurveDisplay
from sklearn.svm import SVC
from sklearn.datasets import fetch_openml
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import ShuffleSplit, GridSearchCV   # Hiper parametre için kullanılan kütüphane

dataFrame = pd.read_csv("/content/drive/MyDrive/diabetes.csv")

df1 = dataFrame.copy()

df1 = pd.DataFrame(df1)

df1.head()

df1.info()

df1.describe().T

# bu değerden kişilerin diyabet olanarı ve olmayanlarını direk görüyoruz 
df1["Outcome"].value_counts()

f,ax=plt.subplots(1,2,figsize=(10,5))
df1['Outcome'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('Dağılım')
ax[0].set_ylabel('')
sns.countplot('Outcome',data=df1,ax=ax[1])
ax[1].set_title('Outcome')
plt.show()

df1.isnull().sum()  # null değer gözükmüyor

df1.where(df1["Pregnancies"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["Glucose"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["BloodPressure"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["SkinThickness"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["Insulin"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["BMI"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["DiabetesPedigreeFunction"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

df1.where(df1["Age"] == 0).value_counts().sum()        # öznitelikler içindeki sıfır değerleri buluyoruz

""" * Insulin ve SkinThickness sütunaları tamamen kaldırıldı 
 * Glucose, BloodPressure,BMI sıfır olan satırları kaldırıldı
"""

df1[["Glucose","BloodPressure",
     "BMI"]] = df1[["Glucose","BloodPressure",
     "BMI"]].replace(0,np.NaN)
df1.isnull().sum()

msno.bar(df1,figsize=(10,8))
plt.show()

df1 = df1.drop("Insulin", axis='columns')
# hocanın sütun olarak çıkartın dediği veriler

df1 = df1.drop("SkinThickness", axis='columns')

df1.dropna(inplace = True)

df1.info()

"""## Veri Setini Dengeli Hale Getirme"""

# Standartlaştırma 
rob_scaler = RobustScaler()
df1['Pregnancies'] = rob_scaler.fit_transform(df1['Pregnancies'].values.reshape(-1,1))
df1['Glucose'] = rob_scaler.fit_transform(df1['Glucose'].values.reshape(-1,1))
df1['BloodPressure'] = rob_scaler.fit_transform(df1['BloodPressure'].values.reshape(-1,1))
df1['BMI'] = rob_scaler.fit_transform(df1['BMI'].values.reshape(-1,1))
df1['DiabetesPedigreeFunction'] = rob_scaler.fit_transform(df1['DiabetesPedigreeFunction'].values.reshape(-1,1))
df1['Age'] = rob_scaler.fit_transform(df1['Age'].values.reshape(-1,1))
df1.head()

# veri setini train ve test olarak ayırıyoruz
X = df1.drop("Outcome", axis=1)
y = df1["Outcome"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123456)

print(X_train.info())
print(X_train.shape)
print('_'*40)
print(X_test.info())
print(X_test.shape)
print('_'*40)
print(y_train.head())
print(y_train.shape)
print('_'*40)
print(y_test.head())
print(y_test.shape) #bunuda kullanabiliriz

y_train.value_counts()  #dengesiz veri seti

# Smote uygulanması (Eğitim setine uygulanıyor)
oversample = SMOTE()
X_smote, y_smote = oversample.fit_resample(X_train, y_train)

y_smote.value_counts()    # dengeli veri seti

"""## Veri görselleştirme"""

dataR = pd.concat([X_smote,y_smote], axis=1)

dataR["Outcome"] = pd.Categorical(dataR["Outcome"])

corrSpearman = dataR.corr(method="spearman")

figure = plt.figure(figsize=(10,8))
sns.heatmap(corrSpearman,cmap="RdYlGn",vmax=1,vmin=-1,center=0,annot=True)
plt.show()

# korelasyon ile öznitelikler arasındaki orantılar incelendi

dataR[0:8].hist(figsize=(10,10), density=True)
plt.show()

figure = plt.figure(figsize=(10,5))
sns.boxplot(x="Pregnancies",y="Outcome",data=dataR)
plt.show()

sns.set_theme(style="ticks")
exercise = sns.load_dataset("exercise")
g = sns.catplot(x="Outcome", y="Glucose",data=dataR)

ax = sns.barplot(x="Outcome", y="BloodPressure", data=dataR)

sns.violinplot(x="Outcome", y="BloodPressure", data=dataR, size=6)

sns.jointplot(x="BMI", y="Age", data=dataR, height=8)

dataR.plot(kind="scatter", x="BMI", y="DiabetesPedigreeFunction") # Ortalama ile dolan verilerin dağılımı belli oluyor

figure = plt.figure(figsize=(20,8))
sns.jointplot(x="Pregnancies",y="DiabetesPedigreeFunction", color="#4CB391",hue="Outcome",data=dataR)
plt.show()

figure = plt.figure(figsize=(10,5))
sns.lineplot(x="Age",y="Pregnancies",hue="Outcome",data=dataR)
plt.show()

# ortalamayı ve ortalama etrafında %95 güven aralığını çizerek her bir değerdeki çoklu ölçümleri toplamaktır
# özellikle daha büyük verilerle, bir güven aralığı yerine 
# standart sapmayı çizerek her zaman noktasında dağılımın yayılmasını temsil etmektir

sns.FacetGrid(dataR, hue="Outcome", height=6) \
   .map(sns.kdeplot, "BloodPressure") \
   .add_legend()

sns.FacetGrid(dataR, hue="Outcome", height=7) \
   .map(plt.scatter, "BloodPressure", "Glucose") \
   .add_legend()

sns.jointplot(data=dataR, x="BloodPressure", y="BMI", kind="reg")

plt.figure(figsize=(15,5))
pd.plotting.parallel_coordinates(dataR,'Outcome',color=('gold','blue'))
plt.xticks(rotation=0)

sns.pairplot(dataR.drop("Pregnancies", axis=1), hue="Outcome", height=1.9)
# outcome değerlerine göre tüm niteliklerin gösterimi

from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(10,5))
ax = Axes3D(fig)
m= ax.scatter(dataR["Glucose"], dataR["Age"], dataR["Pregnancies"],s=20, alpha=0.9)
plt.title("simple 3D scatter plot")
ax.set_xlabel('Glucose', fontweight ='bold')
ax.set_ylabel('Age', fontweight ='bold')
ax.set_zlabel('Pregnancies', fontweight ='bold')

plt.show()

import plotly.graph_objects as go
fig = go.Figure(data=[go.Mesh3d(x=dataR["Age"],
                   y=dataR["Pregnancies"],
                   z=dataR["Glucose"],
                   opacity=0.5,
                   color='rgba(244,22,100,0.6)'
                  )])

fig.update_layout(scene = dict(
                    xaxis_title='Age',
                    yaxis_title='Pregnancies',
                    zaxis_title='Glucose'))

fig.show()

fig = go.Figure(data=[go.Mesh3d(x=dataR["Glucose"],
                   y=dataR["BMI"],
                   z=dataR["Age"],
                   opacity=0.5,
                   color='rgba(244,22,100,0.6)'
                  )])

fig.update_layout(scene = dict(
                    xaxis_title='Glucose',
                    yaxis_title='BMI',
                    zaxis_title='Insulin'))

fig.show()

#import plotly.express as px
#fig = px.scatter(dataR, x='Age', y='Glucose', color='Outcome', size='BMI',
#                facet_col='BloodPressure', facet_col_wrap=4)
#fig.show()

"""## Makine öğrenmesi Modelleri :

* Projemiz çıktılarında kıyaslama yapılacaksa ; 
* TP: 1 değerinin 1 olarak tahmin edilmesi 
* TN: 0 değerlerini 0 olarak tahmin edilmesi 
* FP: 0 değerlerinin 1 olarak tahmin edilmesi
* FN: 1 değerlerinin o olarak tahmin edilmesi 

* Accuracy = TP+TN/TP+FP+FN+TN
* precision: TP / TP+FP 
* recall: TP / TP+FN
* F1 Score = 2*(Recall * Precision) / (Recall + Precision)
* Mikro ortalama: Precision ve recall score, modelin bireysel sınıfların gerçek pozitiflerinden (TP'ler), gerçek negatiflerinden (TN'ler), yanlış pozitiflerinden (FP'ler) ve yanlış negatiflerinden (FN'ler) hesaplanır.
* Makro-ortalama: Precision ve recall score, bireysel sınıfların precision ve recall score puanlarının aritmetik ortalaması olarak hesaplanır.
* Weighted Average (Ağırlıklı Ortalama): Ağırlıklı ortalama, bir veri setindeki sayıların değişen önem derecelerini hesaba katan bir hesaplamadır.Ağırlıklı ortalama hesaplanırken, son hesaplama yapılmadan önce veri setindeki her sayı önceden belirlenmiş bir ağırlıkla çarpılır.Basit bir ortalama veya aritmetik ortalama hesaplanırken, tüm sayılar eşit olarak ele alınır ve eşit ağırlık verilir. Ancak ağırlıklı ortalama, her bir veri noktasının göreli önemini önceden belirleyen ağırlıklar atar.

### GaussianNB
"""

gaussianNB = GaussianNB()
gaussianNB = gaussianNB.fit(X_smote, y_smote)

train_pred_gaussianNB = gaussianNB.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_gaussianNB)*100))

print("Confusion Matrix-GaussianNB-Train: ")
print(confusion_matrix(y_train, train_pred_gaussianNB))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_gaussianNB))

print("-"*40)

test_pred_gaussianNB = gaussianNB.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_gaussianNB)*100))

print("Confusion Matrix-GaussianNB-Test: ")
print(confusion_matrix(y_test, test_pred_gaussianNB))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_gaussianNB))

param_grid_nb = {
    'var_smoothing': np.logspace(-10,1, num=200)
}

cv = GridSearchCV(GaussianNB(),param_grid_nb,scoring = 'accuracy', cv=5,verbose=False,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train , train_pred_gaussianNB)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_gaussianNB)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### BernoulliNB"""

bernoulliNB = BernoulliNB()
bernoulliNB.fit(X_smote, y_smote)

train_pred_bernoulliNB = bernoulliNB.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_bernoulliNB)*100))

print("Confusion Matrix-BernoulliNB-Train: ")
print(confusion_matrix(y_train, train_pred_bernoulliNB))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_bernoulliNB))

print("-"*40)


test_pred_bernoulliNB = bernoulliNB.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_bernoulliNB)*100))

print("Confusion Matrix-BernoulliNB-Test: ")
print(confusion_matrix(y_test, test_pred_bernoulliNB))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_bernoulliNB))

param = [{
    'alpha':[0.001,0.01,0.1,1.0,10.0],
    'binarize':[0.0,1.0,5.0,10.],
    'fit_prior':[True,False]
    
}]

cv = GridSearchCV(BernoulliNB(),param,scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_bernoulliNB)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_bernoulliNB)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### LogisticRegression"""

logisticRegression = LogisticRegression(random_state=123456)
logisticRegression.fit(X_smote, y_smote)


train_pred_logisticRegression = logisticRegression.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_logisticRegression)*100))

print("Confusion Matrix-LogisticRegression-Train: ")
print(confusion_matrix(y_train, train_pred_logisticRegression))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_logisticRegression))

print("-"*40)

test_pred_logisticRegression = logisticRegression.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_logisticRegression)*100))

print("Confusion Matrix-LogisticRegression-Test: ")
print(confusion_matrix(y_test, test_pred_logisticRegression))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_logisticRegression))

param ={"C":np.logspace(20,40,60), "penalty":["l2","none"]}  # logistic regresyon tekrar bak 

cv = GridSearchCV(LogisticRegression(), param, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_logisticRegression)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_logisticRegression)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### DecisionTree"""

decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_smote, y_smote)

train_pred_decision_tree = decision_tree.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_decision_tree)*100))

print("Confusion Matrix-DecisionTreeClassifier-Train: ")
print(confusion_matrix(y_train, train_pred_decision_tree))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_decision_tree))

print("-"*40)

test_pred_decision_tree = decision_tree.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_decision_tree)*100))

print("Confusion Matrix-DecisionTreeClassifier-Test: ")
print(confusion_matrix(y_test, test_pred_decision_tree))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_decision_tree))

param_decision_tree = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}

cv = GridSearchCV(DecisionTreeClassifier(), param_decision_tree, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_decision_tree)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_decision_tree)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### RandomForest"""

randomForest = randomForest()
randomForest.fit(X_smote,y_smote)

train_pred_randomForest = randomForest.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_randomForest)*100))
print("Confusion Matrix-randomForest-Train: ")
print(confusion_matrix(y_train, train_pred_randomForest))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_randomForest))

print("-"*40)

test_pred_randomForest = randomForest.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_randomForest)*100))

print("Confusion Matrix-randomForest-Test: ")
print(confusion_matrix(y_test, test_pred_randomForest))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_randomForest))

param_grid = {
    'bootstrap': [True,False],
    'max_depth': [80, 90, 100],
    #'max_features': [2,3,4],
    'min_samples_leaf': [1,2,3,4],
    'min_samples_split': [1,2,3,5,9],
    'n_estimators': [100, 200, 300]
}

cv = GridSearchCV(RandomForestClassifier(), param_grid, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_randomForest)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_randomForest)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### GradientBoosting"""

gradientBoosting = gradientBoosting()
gradientBoosting.fit(X_smote, y_smote)

train_pred_gradientBoosting = gradientBoosting.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_gradientBoosting)*100))

print("Confusion Matrix-gradientBoosting-Train: ")
print(confusion_matrix(y_train, train_pred_gradientBoosting))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_gradientBoosting))

print("-"*40)

test_pred_gradientBoosting = gradientBoosting.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_gradientBoosting)*100))

print("Confusion Matrix-gradientBoosting-Test: ")
print(confusion_matrix(y_test, test_pred_gradientBoosting))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_gradientBoosting))

parameters = {
    "loss":["deviance"],
    "learning_rate": [0.01,0.1,0.5],
    "min_samples_split": np.linspace(0.1, 0.5, 3),
    "min_samples_leaf": np.linspace(0.1, 0.5, 3),
    "max_depth":[3,5,8],
    "max_features":["log2","sqrt"],
    "criterion": ["friedman_mse",  "mae"],
    "subsample":[0.5,1.0,2.0,5.0],
    "n_estimators":[10]
    }


cv = GridSearchCV(GradientBoostingClassifier(), parameters, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

clf = make_pipeline(StandardScaler(), GradientBoostingClassifier())
clf.fit(X_smote,y_smote)
y_score = clf.decision_function(X_smote)

fpr, tpr, _ = roc_curve(y_smote, y_score, pos_label=clf.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

clf = make_pipeline(StandardScaler(), GradientBoostingClassifier())
clf.fit(X_smote,y_smote)
y_score = clf.decision_function(X_test)

fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=clf.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

"""### xcBoost """

xgBoost = xgBoost(use_label_encoder=False,eval_metric = 'error')

xgBoost.fit(X_smote, y_smote)

train_pred_xgBoost = xgBoost.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_xgBoost)*100))

print("Confusion Matrix-xgBoost-Train: ")
print(confusion_matrix(y_train, train_pred_xgBoost))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_xgBoost))

print("-"*40)

test_pred_xgBoost = xgBoost.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_xgBoost)*100))

print("Confusion Matrix-xgBoost-Test: ")
print(confusion_matrix(y_test, test_pred_xgBoost))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_xgBoost))

params = {
        'min_child_weight': [1, 5, 10],
        'gamma': [-1,0,1,2,3],
        'subsample': [0,1,2,3],
        'colsample_bytree': [0,1,2,3,4],
        'max_depth': [2,3, 4]
        }

cv = GridSearchCV(XGBClassifier(), params, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_xgBoost)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_xgBoost)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### SMV"""

sv = svm.SVC(kernel='linear') 
sv.fit(X_smote , y_smote)

train_pred_svm =  sv.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_svm)*100))

print("Confusion Matrix-SVM TRAIN: ")
print(confusion_matrix(y_train, train_pred_svm))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_svm))

print("-"*40)

test_pred_svm = sv.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_svm)*100))

print("Confusion Matrix-SVM TEST: ")
print(confusion_matrix(y_test, test_pred_svm))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_svm))

param_SVC = { 'C': [1.0,10.0,100.0],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
              'degree': [1,2,3],
              'cache_size':[100,200,300],
              'coef0':[0.0,1.0,5.0]
             }

cv = GridSearchCV(SVC(), param_SVC, refit = True, verbose = 1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train, train_pred_svm)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_svm)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### KNN"""

knn = KNeighborsClassifier()
knn.fit(X_smote , y_smote)

train_pred_knn =  knn.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_knn)*100))

print("Confusion Matrix-KNN TRAIN: ")
print(confusion_matrix(y_train, train_pred_knn))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_knn))

print("-"*40)

test_pred_knn = knn.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_knn)*100))

print("Confusion Matrix-KNN TEST: ")
print(confusion_matrix(y_test, test_pred_knn))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_knn))

param_knn = {'n_neighbors': [1,2,3,4,5,10], 
             'weights': ['uniform', 'distance'],
             'metric': ['euclidean', 'manhattan']}
cv = GridSearchCV(KNeighborsClassifier(), param_knn, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train , train_pred_knn)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_knn)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

"""### MLP """

mlp = MLPClassifier(max_iter=1000)
mlp.fit(X_smote , y_smote)


train_pred_mlp =  mlp.predict(X_train)
print('Train Accuracy : %.3f%% ' % (accuracy_score(y_train , train_pred_mlp)*100))

print("Confusion Matrix-KNN TRAIN: ")
print(confusion_matrix(y_train, train_pred_mlp))

print('\nModel Sonuçları\n')
print(classification_report(y_train, train_pred_mlp))

print("-"*40)

test_pred_mlp = mlp.predict(X_test)
print('Test Accuracy  : %.3f%% ' % (accuracy_score(y_test, test_pred_mlp)*100))

print("Confusion Matrix-KNN TEST: ")
print(confusion_matrix(y_test, test_pred_mlp))

print('\nModel Sonuçları\n')
print(classification_report(y_test, test_pred_mlp))

param_MLP = {
             'hidden_layer_sizes': [(10,30,10),(20,)],
             'activation': ['tanh', 'relu'],
             'solver': ['sgd', 'adam','lbfgs'],
             'alpha': [0.0001, 0.05],
             'learning_rate': ['constant','adaptive']
}

cv = GridSearchCV(MLPClassifier(max_iter=500), param_MLP, scoring = 'accuracy', cv=5,n_jobs=-1).fit(X_smote,y_smote)
print(cv.best_params_)
print(cv.best_score_)

fpr , tpr , thresolds = metrics.roc_curve(y_train , train_pred_mlp)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

fpr , tpr , thresolds = metrics.roc_curve(y_test, test_pred_mlp)
roc_auc = metrics.auc(fpr , tpr)
plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)
roc_auc

from sklearn.metrics import plot_roc_curve

plot_roc_curve(cv,X_train,y_train)

"""### deneme """

clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))
clf.fit(X_smote,y_smote)
y_score = clf.decision_function(X_smote)

fpr, tpr, _ = roc_curve(y_smote, y_score, pos_label=clf.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()
roc_display

